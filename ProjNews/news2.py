import streamlit as st
import pandas as pd
import feedparser
from urllib.parse import quote
from bs4 import BeautifulSoup
from konlpy.tag import Okt
from sentence_transformers import SentenceTransformer, util
from transformers import pipeline
from wordcloud import WordCloud
import plotly.express as px
import matplotlib.pyplot as plt
from datetime import datetime
import os
from googletrans import Translator
from fpdf import FPDF
from io import BytesIO

# 1. ëª¨ë¸ ë¡œë”©
@st.cache_resource
def load_models():
    summarizer = SentenceTransformer("jhgan/ko-sroberta-multitask")
    sentiment_ko = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")
    sentiment_en = pipeline("sentiment-analysis", model="distilbert-base-uncased-finetuned-sst-2-english")
    okt = Okt()
    return summarizer, sentiment_ko, sentiment_en, okt

summarizer, sentiment_ko, sentiment_en, okt = load_models()
translator = Translator()

# ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ğŸ§  AI ìš”ì•½ ë‰´ìŠ¤ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸ“° AI ë‰´ìŠ¤ ìš”ì•½ ëŒ€ì‹œë³´ë“œ")
st.caption("ìš”ì•½ Â· ê°ì •ë¶„ì„ Â· í‚¤ì›Œë“œ ì¶”ì¶œ Â· ê°ì •ë¶„í¬ Â· ì‹œê³„ì—´ Â· PDF ì €ì¥ê¹Œì§€ í•œ ë²ˆì—")

# í•„í„°
KEYWORDS = ["AI", "ë¡œë´‡", "ë¡œë´‡ì„±ê²©", "ë¡œë´‡ê°ì •", "IT"]
selected_keywords = st.sidebar.multiselect("ğŸ” í‚¤ì›Œë“œ ì„ íƒ", KEYWORDS, default=KEYWORDS)
extra_kw = st.sidebar.text_input("â• ì¶”ê°€ í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)")
if extra_kw:
    selected_keywords += [kw.strip() for kw in extra_kw.split(",") if kw.strip()]
lang_option = st.sidebar.radio("ğŸŒ ì–¸ì–´", ["í•œêµ­ì–´", "ì˜ì–´"])
max_items = st.sidebar.slider("ğŸ“° í‚¤ì›Œë“œë‹¹ ë‰´ìŠ¤ ìˆ˜", 1, 10, 5)
start_date = st.sidebar.date_input("ğŸ“… ì‹œì‘ ë‚ ì§œ", None)
end_date = st.sidebar.date_input("ğŸ“… ì¢…ë£Œ ë‚ ì§œ", None)
view_type = st.sidebar.radio("ğŸ—‚ ë³´ê¸° ë°©ì‹", ["ì¹´ë“œë·°", "í‘œ"])

if "bookmarks" not in st.session_state:
    st.session_state["bookmarks"] = []

# ìœ í‹¸ í•¨ìˆ˜
def clean_text(html):
    return BeautifulSoup(html, "html.parser").get_text(separator=" ").strip()

def summarize(text, num_sent=2):
    sentences = clean_text(text).replace('!','.').split('. ')
    if len(sentences) <= num_sent: return ' '.join(sentences)
    emb = summarizer.encode(sentences)
    center = emb.mean(axis=0)
    scores = [util.pytorch_cos_sim([center],[e])[0][0] for e in emb]
    top_idx = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:num_sent]
    return '. '.join([sentences[i] for i in sorted(top_idx)])

def extract_keywords(text, n=5):
    nouns = [w for w in okt.nouns(clean_text(text)) if len(w) > 1]
    freq = pd.Series(nouns).value_counts() if nouns else pd.Series([])
    return ', '.join(freq[:n].index) if not freq.empty else ''

def get_sentiment(text, lang="ko"):
    try:
        if lang == "ko":
            result = sentiment_ko(text[:256])
            return result[0]["label"]
        else:
            result = sentiment_en(text)
            return {"POSITIVE":"ê¸ì •", "NEGATIVE":"ë¶€ì •"}.get(result[0]["label"], "ì¤‘ë¦½")
    except:
        return "ì¤‘ë¦½"

def fetch_news(keyword, lang="ko"):
    q = quote(keyword)
    base = f"https://news.google.com/rss/search?q={q}&hl={lang}&gl=KR&ceid=KR:{lang}"
    feed = feedparser.parse(base)
    items = []
    for entry in feed.entries[:max_items]:
        title = entry.title
        link = entry.link
        raw_summary = entry.summary if hasattr(entry, "summary") else title
        date = entry.get("published", datetime.now().strftime("%Y-%m-%d"))
        summary = clean_text(raw_summary)
        if lang == "en":
            summary = translator.translate(summary, dest="ko").text
        sumy = summarize(summary)
        keywords = extract_keywords(summary)
        senti = get_sentiment(summary, lang="ko")
        items.append({
            "í‚¤ì›Œë“œ": keyword, "ì œëª©": title, "ë§í¬": link, "ë‚ ì§œ": date,
            "ìš”ì•½": sumy, "í‚¤ì›Œë“œì¶”ì¶œ": keywords, "ê°ì •": senti
        })
    return pd.DataFrame(items)

df_list = [fetch_news(k, lang="ko" if lang_option=="í•œêµ­ì–´" else "en") for k in selected_keywords]
news_df = pd.concat(df_list).drop_duplicates(subset="ë§í¬")
news_df["ë‚ ì§œ"] = pd.to_datetime(news_df["ë‚ ì§œ"], errors="coerce")

if start_date:
    news_df = news_df[news_df["ë‚ ì§œ"] >= pd.to_datetime(start_date)]
if end_date:
    news_df = news_df[news_df["ë‚ ì§œ"] <= pd.to_datetime(end_date)]

senti_emoji = {'ê¸ì •':'ğŸŸ¢', 'ë¶€ì •':'ğŸ”´', 'ì¤‘ë¦½':'ğŸŸ¡'}
news_df["ê°ì •ì´ëª¨ì§€"] = news_df["ê°ì •"].map(senti_emoji)

# âœ… ì´ ë‰´ìŠ¤ ê±´ìˆ˜ í‘œì‹œ
st.markdown(f"### ğŸ“Š ì´ ë‰´ìŠ¤ ê±´ìˆ˜: {len(news_df)}ê±´")
if news_df.empty:
    st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë‚˜ ë‚ ì§œ í•„í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ì‹œê°í™”
with st.expander("ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„"):
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ‘ğŸ‘ ê°ì • ë¶„í¬")
        st.plotly_chart(px.pie(news_df, names="ê°ì •"))
    with col2:
        st.subheader("ğŸ”¥ ì¸ê¸° í‚¤ì›Œë“œ")
        all_kws = ",".join(news_df["í‚¤ì›Œë“œì¶”ì¶œ"].dropna().values).split(",")
        kw_freq = pd.Series([k.strip() for k in all_kws if k.strip()]).value_counts().head(10)
        st.bar_chart(kw_freq)

    st.subheader("ğŸ“† ê°ì • ì‹œê³„ì—´")
    emo_day = news_df.groupby([news_df["ë‚ ì§œ"].dt.date, "ê°ì •"]).size().unstack().fillna(0)
    st.line_chart(emo_day)

# í‚¤ì›Œë“œë³„ ê°ì • ë¹„êµ
with st.expander("ğŸ†š í‚¤ì›Œë“œ ê°ì • ë¹„êµ"):
    compare_kw = st.multiselect("ë¹„êµí•  í‚¤ì›Œë“œë¥¼ ì„ íƒ", news_df["í‚¤ì›Œë“œ"].unique())
    if compare_kw:
        df_comp = news_df[news_df["í‚¤ì›Œë“œ"].isin(compare_kw)]
        fig = px.histogram(df_comp, x="ê°ì •", color="í‚¤ì›Œë“œ", barmode="group")
        st.plotly_chart(fig)

# ë‰´ìŠ¤ ì¶œë ¥
st.markdown("## ğŸ— ë‰´ìŠ¤ ëª©ë¡")
if view_type == "ì¹´ë“œë·°":
    for _, row in news_df.iterrows():
        with st.container():
            st.markdown(f"### ğŸ“° [{row['ì œëª©']}]({row['ë§í¬']})")
            st.caption(f"ğŸ“… {row['ë‚ ì§œ'].date()}")
            st.markdown(f"ğŸ§¾ {row['ìš”ì•½']}")
            senti = row["ê°ì •"]
            emoji = senti_emoji.get(senti, "")
            st.markdown(f"**ê°ì •:** {emoji} {senti}")
            st.markdown(f"`{row['í‚¤ì›Œë“œì¶”ì¶œ']}`")
            if row["ê°ì •"] == "ë¶€ì •":
                st.warning("ğŸš¨ ì´ ë‰´ìŠ¤ëŠ” ë¶€ì •ì ì¸ ê°ì •ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
            # âœ… ê³ ìœ ì„± ë³´ì¥: í‚¤ì— rowì˜ ë§í¬ í•´ì‹œ ì‚¬ìš©!
            key = f"bm_{abs(hash(row['ë§í¬']))}"
            if st.button("â­ ë¶ë§ˆí¬", key=key):
                if row["ë§í¬"] not in st.session_state["bookmarks"]:
                    st.session_state["bookmarks"].append(row["ë§í¬"])
else:
    st.dataframe(news_df[["í‚¤ì›Œë“œ","ì œëª©","ë‚ ì§œ","ìš”ì•½","ê°ì •","ë§í¬"]], use_container_width=True)

# ë¶ë§ˆí¬ ë³´ê¸° ë° PDF ì €ì¥
with st.expander("ğŸ“© ë¶ë§ˆí¬ ë‰´ìŠ¤ + PDF ì €ì¥"):
    bm_df = news_df[news_df["ë§í¬"].isin(st.session_state["bookmarks"])]
    if not bm_df.empty:
        st.write("â­ ë¶ë§ˆí¬ ë‰´ìŠ¤:")
        for _, row in bm_df.iterrows():
            st.markdown(f"- [{row['ì œëª©']}]({row['ë§í¬']})")
        if st.button("ğŸ“„ ë¶ë§ˆí¬ ë‰´ìŠ¤ PDF ë§Œë“¤ê¸°"):
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", size=12)
            pdf.set_font_size(14)
            pdf.cell(200, 10, txt="ë¶ë§ˆí¬ ë‰´ìŠ¤ ìš”ì•½", ln=1, align='C')
            pdf.set_font_size(10)
            for _, row in bm_df.iterrows():
                entry = (
                    "ğŸ“° ì œëª©     : " + row['ì œëª©'] + "\n"
                    + "ğŸ§¾ ìš”ì•½     : " + row['ìš”ì•½'] + "\n"
                    + "ğŸ·ï¸ í‚¤ì›Œë“œ   : " + row['í‚¤ì›Œë“œì¶”ì¶œ'] + "\n"
                    + "â¤ï¸ ê°ì •     : " + row['ê°ì •'] + " " + senti_emoji.get(row['ê°ì •'], "") + "\n"
                    + "ğŸ”— ë§í¬     : " + row['ë§í¬'] + "\n"
                    + "------------------------------------------------------------\n"
                )
                pdf.multi_cell(0, 10, entry)
            temp = BytesIO()
            pdf.output(temp)
            st.download_button("â¬‡ï¸ PDF ë‹¤ìš´ë¡œë“œ", data=temp.getvalue(), file_name="ë¶ë§ˆí¬_ë‰´ìŠ¤.pdf")
    else:
        st.info("ğŸ“Œ ë¶ë§ˆí¬í•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë‰´ìŠ¤ ì˜† â­ ë²„íŠ¼ìœ¼ë¡œ ì €ì¥í•´ë³´ì„¸ìš”.")